{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ac240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "zalando_20230612.py\n",
    "David Nilsson - Prime Fitness Studio AB\n",
    "2023-06-12\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df91302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e275618",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df98d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# Checking the version of TensorFlow\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from   sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9e968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ce3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To easier optimize the hyperparameters the function build_model() could be used.\n",
    "\n",
    "\"\"\"\n",
    "# Defining a Keras model to search optimized hyper parameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=8, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273d008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e05810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is to load the dataset fashion_mnist\n",
    "\"\"\"\n",
    "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
    "(train_images0, train_labels0), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57169e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda17c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into a training and a test set (20% is validation)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(train_images0, train_labels0, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93fc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5aeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to one-hot encoded format\n",
    "train_labels = to_categorical(train_labels)\n",
    "# Converting the data type of train_labels to integer scalar type\n",
    "train_labels = train_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cab140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to one-hot encoded format\n",
    "test_labels = to_categorical(test_labels)\n",
    "# Convert the data type of train_labels to integer scalar type\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a75d1",
   "metadata": {},
   "source": [
    "Converting the labels to one-hot encoded format\n",
    "val_labels = to_categorical(val_labels)\n",
    "val_labels = val_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2586f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb92521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing that the dataset has ben loaded correctly and what the shapes are of the dataframes\n",
    "\"\"\"\n",
    "# Print som basic information of data set sizes and data sizes\n",
    "train_no,x,y = train_images.shape\n",
    "print('No training images:',train_no, ' with image size:',x,'x',y)\n",
    "label_no = len(train_labels)\n",
    "if (label_no != train_no) : \n",
    "  print('# labels do not match # training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no,x,y = test_images.shape\n",
    "label_no = len(test_labels)\n",
    "print('No test images:',test_no)\n",
    "if (label_no != test_no) : \n",
    "  print('# labels do not match # test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "val_no,x,y = val_images.shape\n",
    "label_no = len(val_labels)\n",
    "print('No val images:',val_no)\n",
    "if (label_no != val_no) : \n",
    "  print('# labels do not match # val images')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c14f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f218b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-processing and reshaping the data to be able to work with training a model\n",
    "\"\"\"\n",
    "# Adding an \"empty\" color dimension for our data sets\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "#val_images = np.expand_dims(val_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ce3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting input shape\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa89eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69415018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "#val_images = (val_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231499b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ca982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As these are images (28x28) it can be interesting to plot some as images\n",
    "image_index = [42, 789] # \"Random\" images to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b340b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in image_index:\n",
    "  #print('Label:', class_names[train_labels[index]])\n",
    "  print('Label:', class_names[train_labels[index][0]])\n",
    "  plt.figure()\n",
    "  plt.imshow(np.squeeze(train_images[index], axis=-1), cmap='gray')\n",
    "  plt.gray()\n",
    "  plt.grid(False)\n",
    "  plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc387340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechaping the input shape of the data\n",
    "input_shape = (28, 28, 1)  # Updating the input shape to 28x28\n",
    "print(\"Input shape\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a89e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc9490b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The Keras model will be the simplest Keras model for NN networks. \n",
    "Working with a sequensial model that can easily be added several layers and\n",
    "have a good overview if not too big.\n",
    "Going for smaller kernel from the start and increasing at the end to gain more\n",
    "abrstraction and capture higher semantic information of the patterns of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a01d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolution layer 1\n",
    "model = Sequential([Conv2D(filters=32, kernel_size=(7, 7), padding='same', activation='relu', input_shape=input_shape),\n",
    "# Adding a MaxPooling2D layer to reduse the data\n",
    "MaxPooling2D(pool_size=(2, 2)),\n",
    "# Add a convolution layer 2\n",
    "Conv2D(filters=32, kernel_size=(11, 11), padding='same', activation='relu', input_shape=input_shape),\n",
    "# Adding a MaxPooling2D layer to reduse the data\n",
    "MaxPooling2D(pool_size=(2, 2)),\n",
    "# Flatten the input to prepare the vector for fully connected layers\n",
    "Flatten(),\n",
    "# Add a hidden Dense layer\n",
    "Dense(units=10, activation='relu'),  # Adjusted units parameter to 10,\n",
    "# Add a an output layer. The output space is the number of classes\n",
    "# Softmax makes the output as probablity vector of the different classes\n",
    "Dense(units=10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15791c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525b957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model, as a preparation for training\n",
    "model.compile(\n",
    "  optimizer='adam',             # Tried: adam, sgd, keras.optimizers.RMSprop(1e-2)\n",
    "  loss='categorical_crossentropy', # sparse_categorical_crossentropy\n",
    "  metrics=['accuracy']                                  # categorical_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31182f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6      ## Number of epoch to run\n",
    "batch_size = 32      ## Mini batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d0be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding a class for an early stopping if there are to little progress in every epoch\n",
    "\"\"\"\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    \n",
    "    #Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "    #Arguments:\n",
    "    #patience: Number of epochs to wait after min has been hit. After this\n",
    "    #number of no improvement, training stops.\n",
    "    \n",
    "\n",
    "    def __init__(self, patience=3):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no lBinaryCrossentropyonger minimum.\n",
    "        self.wait = 5\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab4a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750769bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[EarlyStoppingAtMinLoss()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0541b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Keras tuner based on random search for the model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe4148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the search for the optimum hyperparameters for the model\n",
    "tuner.search(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d769a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best model and its summary\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2c1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fba2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluating the model and plots the performance in terms of accuracy and error\n",
    "\"\"\"\n",
    "epochrange = range(1, epochs + 1)\n",
    "train_acc = history.history['accuracy']\n",
    "test_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4fb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochrange, test_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and testing accuracy (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochrange, test_loss, 'b', label='Test loss')\n",
    "plt.title('Training and test loss (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745bd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the best model\n",
    "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d038ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXERCISE PART 1a\n",
    "Question: \"How many parameters does your model have?\" \n",
    "Answer: The total parameters in my model is: 201 050, and those are all trainable.\n",
    "Trainable parameters are weight coefficients to adjust to better connect the\n",
    "relationship between the the neurons, the neurons themselves and the nodes within \n",
    "the neuron net, both the input layers neurons and the hidden layers nodes.\n",
    "The model becomes overtrained when the error of the validation curve increases unproportional.\n",
    "Based on the graphs, the number of epochs should be where the curve stops following the training \n",
    "error curv.\n",
    "\n",
    "EXERCISE PART 1b\n",
    "Question: \"What test accuracy do you get?\"\n",
    "Answer: 90% validation accuracy at best\n",
    "\n",
    "Issues were identified when Keras tuner were intruduced, by not recognizing the imported \n",
    "libraries. Loading the modules failed constantly by different approaches and libraries. \n",
    "Did not work to use Keras tuner to find a better architecture of the hyperparameters on my \n",
    "local machine (Win 10, VS Code, Anaconda and CMD.\n",
    "\n",
    "Adam optimizer seem to perform well on this Zalando MNIST dataset, and deeper net than approx. \n",
    "10 Conv2D and approx. 10 dense layers led to low alpha in the grcategorp method were activated.\n",
    "\n",
    "around 90% in the validation were achived, and when picking up the best parameter values \n",
    "during the training, 91% in validation were achived.\n",
    "\n",
    "2a\n",
    "Using the earlystopping class to let the model stop if the training and validation not working \n",
    "good enough.\n",
    "I get at better performance of the model when the model is not overtraining.\n",
    "\n",
    "2b, 2c\n",
    "SGT were running onto these gradient issues with deeper layers, and this could probably be \n",
    "due to a more averaging effect through the nets layers. This regulation effect could \n",
    "be beneficial to generalize better to other dataset.\n",
    "\n",
    "3\n",
    "Auto Tune made the hyperparameters work better, and increases the performance at the\n",
    "cost of extended training time. There is need of smart adjustment of the number of layers\n",
    "to test vs. the extra time it takes.\n",
    "\n",
    "Analysis\n",
    "Since the execution stops all the time in Colab and the Keras Tuder not working properly \n",
    "on the local machine, there were hard to find a model that works without flaws.\n",
    "More extensive search for better hyperparameters would be beneficial.\n",
    "Due to the initialization based on randomness, the resultsof the performance differs from \n",
    "time to time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4a091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa30128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d2529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1d32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba7c14",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
