{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "author David Nilsson - Prime Fitness Studio AB\n",
    "2023-04-10 - Deep Learning 7,5 credits\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Importing needed libraries\n",
    "\"\"\"\n",
    "The imported libraries contains classes with methods for different \n",
    "computations and calculations, like linear algebra and plotting \n",
    "data in windows directly on the screen.\n",
    "Tensor flow handles data storage into tensors, higher dimentional matrixes.\n",
    "Keras contains classes for linear algebra for modulating matrixes and\n",
    "creating and modulating machine learning models.\n",
    "Numpy is containing classes for mathematical computations.\n",
    "Matplotlib is containing classes for plotting data in windows on screen.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "\n",
    "# print('Keras version:',tensorflow.keras.__version__)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from   sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matlab plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "No GPU was accessible on my computers, and hence, only CPU were used to\n",
    "do the computations for training and validating the models.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Importing the data set to work with, from keras databases by open API into dataframes\n",
    "\"\"\"\n",
    "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
    "(train_images0, train_labels0), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Define a list of the labels of the data\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Split the training set into a training and a validation set (20% is validation)\n",
    "\"\"\"\n",
    "The train data should be around 60-80% of the total data, and a separate data set \n",
    "should be used vor testing, or validation of the model. These data should not be mixed.\n",
    "Here the data is splitted to 80/20.\n",
    "\"\"\"\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images0, train_labels0, test_size=0.20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print som basic information of data set sizes and data sizes\n",
    "\"\"\"\n",
    "Displaying information about the data (zalando MNIST-dataset).\n",
    "\"\"\"\n",
    "train_no,x,y = train_images.shape\n",
    "print('No training images:',train_no, ' with image size:',x,'x',y)\n",
    "label_no = len(train_labels)\n",
    "if (label_no != train_no) : \n",
    "  print('# labels do not match # training images')\n",
    "\n",
    "test_no,x,y = test_images.shape\n",
    "label_no = len(test_labels)\n",
    "print('No test images:',test_no)\n",
    "if (label_no != test_no) : \n",
    "  print('# labels do not match # test images')\n",
    "\n",
    "val_no,x,y = val_images.shape\n",
    "label_no = len(val_labels)\n",
    "print('No val images:',val_no)\n",
    "if (label_no != val_no) : \n",
    "  print('# labels do not match # val images')\n",
    "\n",
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Preparing the data (pictures) to be able to pass through the deep learning net.\n",
    "\"\"\"\n",
    "# Add an \"empty\" color dimension for our data sets\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "val_images = np.expand_dims(val_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "val_images = (val_images / 255) - 0.5\n",
    "\n",
    "\n",
    "\n",
    "# As these are images (28x28) it can be interesting to plot some as images\n",
    "\"\"\"\n",
    "Displaying 2 pictures of the data as the pictures after preparation as low resolution pictures.\n",
    "\"\"\"\n",
    "image_index = [42, 789] # \"Random\" images to print\n",
    "\n",
    "for index in image_index:\n",
    "  print( 'Label:', class_names[train_labels[index]])\n",
    "  plt.figure()\n",
    "  plt.imshow(np.squeeze(train_images[index], axis=-1))\n",
    "  plt.gray()\n",
    "  plt.grid(False)\n",
    "  plt.show(block=False)\n",
    "  \n",
    "  \n",
    "  \n",
    "# We need to give the input shape (i.e. our image shape) to our model\n",
    "input_shape = test_images[0].shape\n",
    "print(\"Input shape\", input_shape)\n",
    "\n",
    "# The Keras model will be the simplest Keras model for NN networks. \n",
    "# It is a single stack of layers connected sequentially.\n",
    "\"\"\"\n",
    "Were trying out several different variants and number of convolutional and dense \n",
    "layers and different sizes of kernels.\n",
    "Got the best results by having smaller kernels (3, 3) and 10 convolutional layers and \n",
    "10 fully connected layers. Regular ReLu activation function were used on every layer \n",
    "instead of sigmoid or similar. this reduces the computations and minimizes the risk of\n",
    "the learning rate drop to zero as the net gets deeper.\n",
    "Between the convolutional and the fully connected layers there has to be a flattening layer.\n",
    "The softmax function at the end normalizes the data from the last layer between 0-1.\n",
    "\"\"\"\n",
    "model = Sequential([\n",
    "\n",
    "# Add a convolution layer\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 1\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 2\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 3\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 4\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 5\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 6\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 7\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 8\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "# Add a convolution layer 9\n",
    "Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "\n",
    "\n",
    "# Flatten the input. This prepares the vector for fully connected layers.\n",
    "Flatten(),\n",
    "\n",
    "# Add a hidden Dense layer\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer1\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer2\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer3\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer4\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer5\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer6\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer7\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer8\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "# Add a hidden Dense layer9\n",
    "Dense(units=16, activation='relu'),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add a an output layer. The output space is the number of classes\n",
    "#    Softmax makes the output as probablity vector of the different classes\n",
    "Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model, as a preparation for training\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "epochs = 15      ## Number of epoch to run\n",
    "batch_size = 32  ## Mini batch size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Class to stop the training if the training goes to slow.\n",
    "    Parameter \"patience\" is the number of epochs to wait until stop, if no progress\n",
    "    is made in the training results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience=3):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "\n",
    "\n",
    "\n",
    "# Train the model.\n",
    "\"\"\"\n",
    "Starts the model training, and has the ability to abort the training with the\n",
    "callback, and lets me know if abort is done because of slow progress by the\n",
    "parameter \"verbose\".\n",
    "\"\"\"\n",
    "history = model.fit(\n",
    "  train_images, to_categorical(train_labels),\n",
    "  epochs=epochs,\n",
    "  batch_size=batch_size,\n",
    "  verbose = 1,\n",
    "  validation_data=(val_images, to_categorical(val_labels)),\n",
    "  callbacks=[EarlyStoppingAtMinLoss()],\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Preparing data and plotting the result from training and validation.\n",
    "\"\"\"\n",
    "epochrange = range(1, epochs + 1)\n",
    "train_acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model.\n",
    "\"\"\"\n",
    "Printing out the validation performance of the model.\n",
    "\"\"\"\n",
    "test_loss, test_acc = model.evaluate(test_images,to_categorical(test_labels))\n",
    "print('Test accuracy: %.3f' % test_acc)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "EXERCISE PART 1a\n",
    "Question: \"How many parameters does your model have?\" \n",
    "Answer: The total parameters in my model is: 201 050 to approx. 420 000, and those are all trainable.\n",
    "Trainable parameters are weight coefficients to adjust to better connect the\n",
    "relationship between the the neurons, the neurons themselves and the nodes within \n",
    "the neuron net, both the input layers neurons and the hidden layers nodes.\n",
    "\n",
    "EXERCISE PART 1b\n",
    "Question: \"What test accuracy do you get?\"\n",
    "Answer: At best 91%, but differs from time to time. Less overtraining after this setup.\n",
    "\n",
    "EXERCISE PART 2a\n",
    "Used an early stopper by callback.\n",
    "\n",
    "EXERCISE PART 2b\n",
    "\n",
    "EXERCISE PART 2c\n",
    "\n",
    "EXERCISE PART 3\n",
    "\"\"\"\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
