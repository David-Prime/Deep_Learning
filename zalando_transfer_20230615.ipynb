{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307bc2e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "zalando_transfer_20230615.py\n",
    "David Nilsson - Prime Fitness Studio AB\n",
    "2023-06-15\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed02f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries  \n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import subprocess\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "import keras_tuner as kt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from tensorboard.plugins.profile import profiler_v2 as profiler # Does not work locally neither in Colab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To easier optimize the hyperparameters the function build_model() is used\n",
    "\n",
    "\"\"\"\n",
    "# Defining a Keras model to search optimized hyper parameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a26f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a folder to store the logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f28ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a callback for the logs\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21692b74",
   "metadata": {},
   "source": [
    "Evaluating at: http://localhost:6006 by command: tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fe1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tf.__version__: \", tf.__version__)\n",
    "print(\"tf.__version__: \", tb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230de0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfac235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print som basic information of data set sizes and data sizes\n",
    "train_no,x,y = train_images.shape\n",
    "print('No training images:',train_no, ' with image size:',x,'x',y)\n",
    "label_no = len(train_labels)\n",
    "if (label_no != train_no) : \n",
    "  print('# labels do not match # training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e157ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no,x,y = test_images.shape\n",
    "label_no = len(test_labels)\n",
    "print('No test images:',test_no)\n",
    "if (label_no != test_no) : \n",
    "  print('# labels do not match # test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63915b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "val_no,x,y = val_images.shape\n",
    "label_no = len(val_labels)\n",
    "print('No val images:',val_no)\n",
    "if (label_no != val_no) : \n",
    "  print('# labels do not match # val images')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91a4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the grayscale images to RGB images with 3 channels\n",
    "#train_ds = tf.data.Dataset.from_tensor_slices((train_images, tf.keras.utils.to_categorical(train_labels, num_classes)))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07def81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds = tf.data.Dataset.from_tensor_slices((test_images, tf.keras.utils.to_categorical(test_labels, num_classes)))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddab52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815635d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
    "#print(\"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds))\n",
    "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedc69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef727fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the grayscale images to RGB images with 3 channels\n",
    "train_images = tf.repeat(train_images[..., tf.newaxis], 3, -1)\n",
    "test_images = tf.repeat(test_images[..., tf.newaxis], 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b0364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the loaded dataset, originally 150*150\n",
    "size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "#validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fa140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data by batches to optimize speed of training and validation\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "#validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e3642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8073b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataset and increasing size by augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.2),]  # 0.2 before\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213f3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the first data-batch after augmentation\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03031549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a base-model / Xception and VGG16 is to big to train\n",
    "base_model = keras.applications.MobileNet(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21948630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze/unfreeze the base_model - Normally False\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "# x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained VGG16 weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b55377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8489926",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)  # Modified output layer\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c05a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243bb40",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the top-layer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fadd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e80fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3600661",
   "metadata": {},
   "source": [
    "Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "since we passed `training=False` when calling it. This means that\n",
    "the batchnorm layers will not update their batch statistics.\n",
    "This prevents the batchnorm layers from undoing all the training\n",
    "we've done so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089818ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last 1 layers of the base_model\n",
    "for layer in base_model.layers[-1:]:\n",
    "    layer.trainable = True\n",
    "# base_model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1708982",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727409eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)  # Modified output layer\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b30ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the top-layer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-5),  # Low learning rate, try also RMSprop\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479685c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03877e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b020615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c27ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Keras tuner based on random search for the model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the search for the optimum hyperparameters for the model\n",
    "#tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "tuner.search(train_ds, to_categorical(train_labels), epochs=10, validation_data=(test_ds, to_categorical(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the best_model\n",
    "best_model.save_weights(\"best_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30fd71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Load the saved weights\n",
    "best_model.load_weights(\"best_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e515321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluating and plotting the performance of the model\n",
    "\"\"\"\n",
    "epochrange = range(1, epochs + 1)\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2534efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8b9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ddcfb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "#test_loss, test_acc = model.evaluate(test_ds)\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "print('Test accuracy: %.3f' % test_acc)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
