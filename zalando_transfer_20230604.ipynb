{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef6aca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "zalando_transfer_20230604.py\n",
    "David Nilsson - Prime Fitness Studio AB\n",
    "2023-06-01\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ab57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries  \n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import subprocess\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "import keras_tuner as kt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from tensorboard.plugins.profile import profiler_v2 as profiler # Does not work locally neither in Colab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dba452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ded5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To easier optimize the hyperparameters the function build_model() could be used.\n",
    "\n",
    "\"\"\"\n",
    "# Defining a Keras model to search optimized hyper parameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd6ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99975537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a folder to store the logs\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a callback for the logs\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334d92a",
   "metadata": {},
   "source": [
    "Evaluating at: http://localhost:6006 by command: tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f81b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344df00b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"tf.__version__: \", tf.__version__)\n",
    "print(\"tf.__version__: \", tb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9df377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Does not work locally neither in Colab\n",
    "\"\"\"\n",
    "# Starting the profiling session to scan for memory losses\n",
    "#tf.profiler.experimental.start('./PythonEnv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ae318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db771ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2274874",
   "metadata": {},
   "source": [
    "subprocess.call(\"tensorboard --logdir logs\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1a643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90152432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset to use\n",
    "# tfds.disable_progress_bar()\n",
    "\"\"\"\n",
    "train_images, val_images, test_images = tfds.load(\n",
    "    \"fashion_mnist\",\n",
    "    # Reserve 10% for validation and 10% for test\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c916cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0526f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7902a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print som basic information of data set sizes and data sizes\n",
    "train_no,x,y = train_images.shape\n",
    "print('No training images:',train_no, ' with image size:',x,'x',y)\n",
    "label_no = len(train_labels)\n",
    "if (label_no != train_no) : \n",
    "  print('# labels do not match # training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no,x,y = test_images.shape\n",
    "label_no = len(test_labels)\n",
    "print('No test images:',test_no)\n",
    "if (label_no != test_no) : \n",
    "  print('# labels do not match # test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68220567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "val_no,x,y = val_images.shape\n",
    "label_no = len(val_labels)\n",
    "print('No val images:',val_no)\n",
    "if (label_no != val_no) : \n",
    "  print('# labels do not match # val images')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d5897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the grayscale images to RGB images with 3 channels\n",
    "#train_ds = train_images.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_ds = val_images.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))\n",
    "#test_ds = test_images.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.repeat(x, 3, axis=-1), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c0db0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56120d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
    "#print(\"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds))\n",
    "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da2cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the first 9 pictures of the dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252defd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0452ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the grayscale images to RGB images with 3 channels\n",
    "train_images = tf.repeat(train_images[..., tf.newaxis], 3, -1)\n",
    "test_images = tf.repeat(test_images[..., tf.newaxis], 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d28af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250aa661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the loaded dataset, originally 150*150\n",
    "size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66da83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "#validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data by batches to optimize speed of training and validation\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bfd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "#validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae6600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the dataset and increasing size by augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.2),]  # 0.2 before\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252547a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the first data-batch after augmentation\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57697061",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a base-model / Xception and VGG16 is to big to train\n",
    "base_model = keras.applications.MobileNet(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec21775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze/unfreeze the base_model - Normally False\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "# x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec98d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained VGG16 weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "# outputs = keras.layers.Dense(1)(x)\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)  # Modified output layer\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d42be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4c8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the top-layer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1817c4e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92006b7e",
   "metadata": {},
   "source": [
    "Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "since we passed `training=False` when calling it. This means that\n",
    "the batchnorm layers will not update their batch statistics.\n",
    "This prevents the batchnorm layers from undoing all the training\n",
    "we've done so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last 1 layers of the base_model\n",
    "for layer in base_model.layers[-1:]:\n",
    "    layer.trainable = True\n",
    "# base_model.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),  # Low learning rate, try also RMSprop\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05358152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843714a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "# outputs = keras.layers.Dense(1)(x)\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)  # Modified output layer\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde13df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the top-layer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),  # Low learning rate, try also RMSprop\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a14c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977080b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaec04c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "\n",
    "# Unfreeze the last 3 layers of the base_model\n",
    "for layer in base_model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "# base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),  # Low learning rate\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=test_ds, callbacks=[tensorboard_callback])\n",
    "\n",
    "model.summary()\n",
    "#saver.save(session, LOG_DIR/model.ckpt, step)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b207d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df20767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8b14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa020e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Keras tuner based on random search for the model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d64fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the search for the optimum hyperparameters for the model\n",
    "#tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "tuner.search(train_ds, to_categorical(train_labels), epochs=10, validation_data=(test_ds, to_categorical(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.build()\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b82cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21146a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be19cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluating and plotting the performance of the model\n",
    "\"\"\"\n",
    "epochrange = range(1, epochs + 1)\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42959fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c40e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss (model 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d05eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08194b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print('Test accuracy: %.3f' % test_acc)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
