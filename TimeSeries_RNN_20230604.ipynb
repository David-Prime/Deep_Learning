{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f40ba1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TimeSeries_RNN_20230604.py\n",
    "David Nilsson - Prime Fitness Studio AB\n",
    "2023-06-04\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70425896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils  import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed9cb7",
   "metadata": {},
   "source": [
    "print('Keras version:',tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "#mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c969d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import os\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from   sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import IPython.display\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb40e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To easier optimize the hyperparameters the function build_model() could be used.\n",
    "\n",
    "\"\"\"\n",
    "# Defining a Keras model to search optimized hyper parameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26234a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions to be called\n",
    "\"\"\"\n",
    "# Help function to get indices for columns based on column names\n",
    "def get_label_columns_indices(dataframe,label_columns=None):\n",
    "  if label_columns is not None:\n",
    "    label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "  else:\n",
    "    label_columns_indices = {name: i for i, name in enumerate(dataframe.columns)}\n",
    "  return label_columns_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba592d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our function that take our time sequence data and convert it to a dataset \n",
    "# that then can be us as a dataset for training or evaluation\n",
    "# Note that this code only implements a target/label width of one, as it seems that timeseries_dataset_from_array only allows for that\n",
    "def datasetgen(dataframe, input_width=24, label_width=1, shift=1, batch_size=8,\n",
    "               label_columns=None, start_index=None, end_index=None, shuffle=False):\n",
    "  offset = input_width+shift-1       # offset to where targets start (and input ends) // Fixed 2023-05-01\n",
    "  input_data = dataframe[:-offset]   # Input up until where the target starts\n",
    "  label_columns_indices = get_label_columns_indices(dataframe,label_columns) # get the selected columns\n",
    "  targets = dataframe[list(label_columns_indices)]\n",
    "  targets = targets[offset:]         # Output from end of input and for the selected columns\n",
    "  # Here we create the windows and store them as a dataset using 'timeseries_dataset_from_array'\n",
    "  train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    input_data, targets, sequence_length=input_width,\n",
    "    sequence_stride=1, sampling_rate=1, batch_size=batch_size, shuffle=shuffle,\n",
    "    start_index=start_index, end_index=end_index)\n",
    "  return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357da243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3dbf8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compile the base model and a callback to stop if no progress\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "def compile_and_fit(model, patience=5):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min',\n",
    "                                                    restore_best_weights = True)\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  start = time.time()\n",
    "  history = model.fit(train_ds, epochs=MAX_EPOCHS,\n",
    "                      validation_data=val_ds,\n",
    "                      callbacks=[early_stopping])\n",
    "  end = time.time()\n",
    "  print(\"Time to run:\", end - start)\n",
    "\n",
    "  return history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d95ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a plot function to show how well it is prediction\n",
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb89af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the trained model against the base_line-model\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "   return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for GPU and determine what GPU we have\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f749f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if not gpu_devices:\n",
    "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
    "              \"accelerator.\")\n",
    "    if \"kaggle_secrets\" in sys.modules:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(\"No !nvidia-smi -L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If possible to run code wiht 16 bits float instad of 32 bits float, this code acitvates such functionality:\n",
    "if gpu_devices:\n",
    " details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    " compute_capability=details.get('compute_capability')\n",
    " print(\"Compute capability:\",compute_capability)\n",
    " if compute_capability[0]>6:\n",
    "   print(\"Turning on mixed_float16\")\n",
    "   policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "   tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168c31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe40536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5005515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This lab will just deal with hourly predictions, so start by sub-sampling the data from 10 minute intervals to 1h:\n",
    "df = df[5::6] # starting from index 5 take every 6th record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f9a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "# Let's take a glance at the data. Here are the first few rows:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e826b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
    "plot_features = df[plot_cols]\n",
    "plot_features.index = date_time\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features = df[plot_cols][:480]\n",
    "plot_features.index = date_time[:480]\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474564f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0efcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the statistics of the loaded data\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a009bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and cleaning the data from unrealistic values\n",
    "wv = df['wv (m/s)']\n",
    "bad_wv = wv == -9999.0\n",
    "wv[bad_wv] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d976f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_wv = df['max. wv (m/s)']\n",
    "bad_max_wv = max_wv == -9999.0\n",
    "max_wv[bad_max_wv] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above inplace edits are reflected in the DataFrame\n",
    "df['wv (m/s)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b4273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca749736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the wind data to be represented as radians to avoid \n",
    "# problems of proximity oc 0 and 360 degrees\n",
    "wv = df.pop('wv (m/s)')\n",
    "max_wv = df.pop('max. wv (m/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to radians.\n",
    "wd_rad = df.pop('wd (deg)')*np.pi / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be11346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the wind x and y components.\n",
    "df['Wx'] = wv*np.cos(wd_rad)\n",
    "df['Wy'] = wv*np.sin(wd_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6561d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the max wind x and y components.\n",
    "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
    "df['max Wy'] = max_wv*np.sin(wd_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2f914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting out the heatmap of the wind-vector\n",
    "plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]')\n",
    "ax = plt.gca()\n",
    "ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71af62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Date Time to be representing seconds instead as a string\n",
    "timestamp_s = date_time.map(datetime.datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6efa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting seconds to \"Time of Day\" and \"Time of Year\" data\n",
    "# This is because the temperature is more likely to shift by variations\n",
    "# over a day and also over a year\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678283ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67782b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the converted time-data\n",
    "plt.plot(np.array(df['Day sin'])[:25])\n",
    "plt.plot(np.array(df['Day cos'])[:25])\n",
    "plt.xlabel('Time [h]')\n",
    "plt.title('Time of day signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the optimal frequences of temperature by time-data\n",
    "# Fast Fourier Transform can be used\n",
    "fft = tf.signal.rfft(df['T (degC)'])\n",
    "f_per_dataset = np.arange(0, len(fft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_h = len(df['T (degC)'])\n",
    "hours_per_year = 24*365.2524\n",
    "years_per_dataset = n_samples_h/(hours_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffc378",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_per_year = f_per_dataset/years_per_dataset\n",
    "plt.step(f_per_year, np.abs(fft))\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 400000)\n",
    "plt.xlim([0.1, max(plt.xlim())])\n",
    "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
    "_ = plt.xlabel('Frequency (log scale)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c55f5c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e065d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Question 1:\n",
    "The two parameters that stands out as containing unrealistic or likely faulty/bad values\n",
    "are minimum wind and minimum value of maximal wind in meter per second. The wind strength can not be -9999 m/s, and \n",
    "this is corrected with setting the value to 0.0 m/s if the value for wind is -9999 in the \n",
    "dataframe. This is the minimum value of the wind.\n",
    "\n",
    "\n",
    "\n",
    "Question 2:\n",
    "The wind direction in degrees is presenting very similar information in wind directions\n",
    "like 0 to 5 compared to 355 to 360 etc., even though they are very similar values in terms\n",
    "of real wind direction. Therefore the wind in degrees are converted into radians.\n",
    "\n",
    "\n",
    "\n",
    "Question 3:\n",
    "Data of time is only important if it is represented in the right frequencies, wich contains \n",
    "shift in the dependent variable (temperature in this case) in days and years. This is because \n",
    "the temperature is likely shifting over a day, and is likely to be similar next day at the \n",
    "same time. This is also likely to be true for the frequency of year. To find these relevant \n",
    "frequencies, a Fast Fourier Transform can be applied to analyse amplitudes of the temperature\n",
    "relative to the time-data. This data is also represented with sinus and cosinus functions, \n",
    "since temperatures are shifting in this form relative time. Then we will have two ways&parameters\n",
    "to represent relaevant time/frequencies. This is adding up the resolution of the models prediction\n",
    "capabilities by a sort of \"triangulation\".\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2282562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index to where we want to split our data into our datasets\n",
    "DataSplitRatios=(0.7,0.2,0.1) # Maybe one should check this sums up to 1?\n",
    "n = len(df)\n",
    "split1ix = int(n*DataSplitRatios[0])\n",
    "split2ix = int(n*(DataSplitRatios[0]+DataSplitRatios[1]))\n",
    "print(split1ix,split2ix,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0698b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data to be able to use the data to train a model\n",
    "train_mean = df[0:split1ix].mean()\n",
    "train_std = df[0:split1ix].std()\n",
    "dfnorm = (df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b10dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the statistics and distribution as standard deviation\n",
    "df_std = dfnorm.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29db67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_label_columns_indices\n",
    "#lcol= ['T (degC)']\n",
    "lcol= None\n",
    "lci = get_label_columns_indices(dfnorm,lcol)\n",
    "print(lci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f15574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the used datasets for part 1\n",
    "lcol=['T (degC)']\n",
    "train_ds = datasetgen(dfnorm, input_width=24, label_width=1, shift=1, \n",
    "              label_columns=lcol, start_index=0, end_index=split1ix)\n",
    "val_ds = datasetgen(dfnorm, input_width=24, label_width=1, shift=1, \n",
    "              label_columns=lcol, start_index=split1ix, end_index=split2ix)\n",
    "test_ds = datasetgen(dfnorm, input_width=24, label_width=1, shift=1, \n",
    "              label_columns=lcol, start_index=split2ix, end_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72b67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish test targets (unroll dataset)\n",
    "test_targets = None\n",
    "for batch in test_ds:\n",
    "  inputs, targets = batch\n",
    "  if test_targets == None:\n",
    "    test_targets = targets\n",
    "  else:\n",
    "   test_targets = tf.concat([test_targets,targets], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And number of features\n",
    "num_target_features = targets.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lci = get_label_columns_indices(dfnorm,lcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0b4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch and look at the shapes for one of the datasets\n",
    "eval_ds = test_ds\n",
    "for batch in eval_ds:\n",
    "  inputs, targets = batch\n",
    "  batchlen = len(inputs)\n",
    "  # We here have a batch of seqlen sequences\n",
    "  print(\"Input shape = {0}, Output shape = {1}\".format(inputs.shape,targets.shape))\n",
    "  break\n",
    "# Print dataset size\n",
    "nobatches = eval_ds.__len__()\n",
    "print(\"No sequences =\", nobatches.numpy() * batchlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95014ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The loss-function in this case, with parametric data and in interval-scale, the \n",
    "size of the error is important to take care of, but the greater the error in the predicted\n",
    "value, the more punished the prediction should be, and this is what Mean Squared Error \n",
    "brings us, since the quadratic operations. Also, it would punish equally if the predicted\n",
    "error is over/under shooting. To measure the predicted value, the absolut value is of relevance, \n",
    "hence the Mean Absolute Accuracy should be used to measure the performance of the trained model.\n",
    "\n",
    "Error: Mean Squared Error\n",
    "Metric: Mean Absolute Accuracy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319681b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4558d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a first simple LSTM model with 128 units\n",
    "lstm_model_baseline = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=False),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=num_target_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eece92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581348a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train this model\n",
    "history_lstm_baseline, lstm_model_baseline = compile_and_fit(lstm_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b50e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ee24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Evaluate the model.\n",
    "test_loss, test_acc = lstm_model_baseline1.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy: %.3f' % test_acc)\n",
    "print('Test loss: %.4f' % test_loss)\n",
    "\n",
    "# Plot the training curves\n",
    "pd.DataFrame(history_lstm_baseline.history).plot(figsize=(8,5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the predictions of temperatures\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), lstm_model_baseline1.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912facaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a the base model to compare with\n",
    "base_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=num_target_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4b7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "history_base_model, base_model = compile_and_fit(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad32441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Comparing the trained model with the baseline model statistically\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanAbsoluteError\n",
    "base_predictions = base_model.predict(eval_ds)\n",
    "trained_predictions = lstm_model_baseline.predict(eval_ds)\n",
    "trained_predictions_gru = better_gru_model_baseline.predict(eval_ds)\n",
    "\n",
    "base_mae = tf.keras.losses.MeanAbsoluteError(test_targets, base_predictions)\n",
    "base_mse = tf.keras.losses.MeanAbsoluteError(test_targets, base_predictions)\n",
    "\n",
    "trained_mae = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions)\n",
    "trained_mse = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions)\n",
    "\n",
    "trained_mae_gru = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions_gru)\n",
    "trained_mse_gru = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions_gru)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f2d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Making the predictions for the test dataset\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "# Extracting the predictions for the desired time steps (24 and 48 hours ahead)\n",
    "prediction_24h = predictions[:, 24, lci['T (degC)']]\n",
    "prediction_48h = predictions[:, 48, lci['T (degC)']]\n",
    "\n",
    "# Printing the predictions of the temperature\n",
    "print(\"Prediction 24 hours ahead:\", prediction_24h)\n",
    "print(\"Prediction 48 hours ahead:\", prediction_48h)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c12eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better LSTM model(s): definition, compile and run, evaluate, and compare!\n",
    "better_lstm_model_baseline = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, recurrent_activation=\"sigmoid\", return_sequences=False),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=num_target_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9338a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ba012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train this model\n",
    "history_better_lstm_baseline, better_lstm_model_baseline = compile_and_fit(better_lstm_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaabcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Evaluate the model.\n",
    "test_loss, test_acc = lstm_model_baseline1.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy: %.3f' % test_acc)\n",
    "print('Test loss: %.4f' % test_loss)\n",
    "\n",
    "# Plot the training curves\n",
    "pd.DataFrame(history_lstm_baseline.history).plot(figsize=(8,5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the predictions of temperatures\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), lstm_model_baseline1.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction\",\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63344fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better GRU model(s): definition, compile and run, evaluate, and compare!\n",
    "better_gru_model_baseline = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, gru_units]\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=True),\n",
    "    tf.keras.layers.GRU(128, recurrent_activation=\"sigmoid\", return_sequences=False),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=num_target_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train this model\n",
    "history_better_gru_model_baseline, better_gru_model_baseline = compile_and_fit(better_gru_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cf471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca112393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Keras tuner based on random search for the model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the search for the optimum hyperparameters for the model\n",
    "#tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "#tuner.search(train_ds, to_categorical(train_labels), epochs=10, validation_data=(test_ds, to_categorical(test_labels)))\n",
    "tuner.search(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea535ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.build()\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab130374",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fd313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting the data\n",
    "\"\"\"\n",
    "# Evaluate the model.\n",
    "test_loss_base_model, test_acc_base_model = base_model.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy base_model: %.3f' % test_acc_base_model)\n",
    "print('Test loss base_model: %.4f' % test_loss_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518139cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves\n",
    "pd.DataFrame(history_base_model.history).plot(figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dca23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8329ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions of temperatures from lstm_model_baseline\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), base_model.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction of base_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da429ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "test_loss_lstm_model_baseline, test_acc_lstm_model_baseline = lstm_model_baseline.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy lstm_model_baseline: %.3f' % test_acc_lstm_model_baseline)\n",
    "print('Test loss lstm_model_baseline: %.4f' % test_loss_lstm_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves\n",
    "pd.DataFrame(history_lstm_model_baseline.history).plot(figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec5d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e757232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions of temperatures from lstm_model_baseline\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), lstm_model_baseline.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction lstm_model_baseline\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220a3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "test_loss_better_lstm_model_baseline, test_acc_better_lstm_model_baseline = better_lstm_model_baseline.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy test_acc_better_lstm_model_baseline: %.3f' % test_acc_better_lstm_model_baseline)\n",
    "print('Test loss test_acc_better_lstm_model_baseline: %.4f' % test_loss_better_lstm_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d86a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves\n",
    "pd.DataFrame(history_better_lstm_model_baseline.history).plot(figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c733f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f232f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions of temperatures\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), better_lstm_model_baseline.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction test_acc_better_lstm_model_baseline\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "test_loss_better_gru_model_baseline, test_acc_better_gru_model_baseline = better_gru_model_baseline.evaluate(test_ds, verbose=0)\n",
    "print('Test accuracy test_acc_better_gru_model_baseline: %.3f' % test_acc_better_gru_model_baseline)\n",
    "print('Test loss test_acc_better_gru_model_baseline: %.4f' % test_loss_better_gru_model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves\n",
    "pd.DataFrame(history_better_gru_baseline.history).plot(figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b32011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b746376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions of temperatures\n",
    "for x, y in val_ds.take(3):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), better_gru_model_baseline.predict(x)[0]],\n",
    "        1,\n",
    "        \"Single Step Prediction test_acc_better_gru_model_baseline\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee85ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation of the models\n",
    "\"\"\"\n",
    "# Comparing the trained model with the baseline model statistically\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanAbsoluteError\n",
    "base_predictions = base_model.predict(eval_ds)\n",
    "trained_predictions_lstm = lstm_model_baseline.predict(eval_ds)\n",
    "better_trained_predictions_lstm = better_lstm_model_baseline.predict(eval_ds)\n",
    "better_trained_predictions_gru = better_gru_model_baseline.predict(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mae = tf.keras.losses.MeanAbsoluteError(test_targets, base_predictions)\n",
    "base_mse = tf.keras.losses.MeanAbsoluteError(test_targets, base_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_mae_lstm = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions_lstm)\n",
    "trained_mse_lstm = tf.keras.losses.MeanAbsoluteError(test_targets, trained_predictions_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_trained_mae_lstm = tf.keras.losses.MeanAbsoluteError(test_targets, better_trained_predictions_lstm)\n",
    "better_trained_mse_lstm = tf.keras.losses.MeanAbsoluteError(test_targets, better_trained_predictions_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_trained_mae_gru = tf.keras.losses.MeanAbsoluteError(test_targets, better_trained_predictions_gru)\n",
    "better_trained_mse_gru = tf.keras.losses.MeanAbsoluteError(test_targets, better_trained_predictions_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa677cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions of the models\n",
    "\"\"\"\n",
    "# Making the predictions for the test dataset\n",
    "predictions_base_model = base_model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predictions for the desired time steps (25 and 48 hours ahead)\n",
    "predictions_base_model_25h = predictions_base_model[:, 25, lci['T (degC)']]\n",
    "predictions_base_model_48h = predictions_base_model[:, 48, lci['T (degC)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the predictions of the temperature\n",
    "print(\"predictions_base_model 25 hours ahead:\", predictions_base_model_25h)\n",
    "print(\"predictions_base_model 48 hours ahead:\", predictions_base_model_48h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d4828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09885dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions for the test dataset\n",
    "predictions_lstm_model_baseline = lstm_model_baseline.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predictions for the desired time steps (25 and 48 hours ahead)\n",
    "predictions_lstm_model_baseline_25h = predictions_lstm_model_baseline[:, 25, lci['T (degC)']]\n",
    "predictions_lstm_model_baseline_48h = predictions_lstm_model_baseline[:, 48, lci['T (degC)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the predictions of the temperature\n",
    "print(\"predictions_lstm_model_baseline 25 hours ahead:\", predictions_lstm_model_baseline_25h)\n",
    "print(\"predictions_lstm_model_baseline 48 hours ahead:\", predictions_lstm_model_baseline_48h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3f368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fcfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions for the test dataset\n",
    "predictions_better_lstm_model_baseline = better_lstm_model_baseline.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predictions for the desired time steps (25 and 48 hours ahead)\n",
    "predictions_better_lstm_model_baseline_25h = predictions_better_lstm_model_baseline[:, 25, lci['T (degC)']]\n",
    "predictions_better_lstm_model_baseline_48h = predictions_better_lstm_model_baseline[:, 48, lci['T (degC)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the predictions of the temperature\n",
    "print(\"predictions_better_lstm_model_baseline 25 hours ahead:\", predictions_better_lstm_model_baseline_25h)\n",
    "print(\"predictions_better_lstm_model_baseline 48 hours ahead:\", predictions_better_lstm_model_baseline_48h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed29069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa37947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions for the test dataset\n",
    "predictions_better_gru_model_baseline = better_gru_model_baseline.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the predictions for the desired time steps (25 and 48 hours ahead)\n",
    "predictions_better_gru_model_baseline_25h = predictions_better_gru_model_baseline[:, 25, lci['T (degC)']]\n",
    "predictions_better_gru_model_baseline_48h = predictions_better_gru_model_baseline[:, 48, lci['T (degC)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the predictions of the temperature\n",
    "print(\"predictions_better_gru_model_baseline 25 hours ahead:\", predictions_better_gru_model_baseline_25h)\n",
    "print(\"predictions_better_gru_model_baseline 48 hours ahead:\", predictions_better_gru_model_baseline_48h)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
